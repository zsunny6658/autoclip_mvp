"""
Step 5: ä¸»é¢˜èšç±» - å°†ç›¸å…³ç‰‡æ®µèšåˆä¸ºåˆé›†
"""
import json
import logging
from typing import List, Dict, Optional
from pathlib import Path

from ..utils.llm_factory import LLMFactory
from ..config import PROMPT_FILES, METADATA_DIR, MAX_CLIPS_PER_COLLECTION

logger = logging.getLogger(__name__)

class ClusteringEngine:
    """ä¸»é¢˜èšç±»å¼•æ“"""
    
    def __init__(self, metadata_dir: Optional[Path] = None, prompt_files: Dict = None):
        self.llm_client = LLMFactory.get_default_client()
        
        # åŠ è½½æç¤ºè¯
        prompt_files_to_use = prompt_files if prompt_files is not None else PROMPT_FILES
        with open(prompt_files_to_use['clustering'], 'r', encoding='utf-8') as f:
            self.clustering_prompt = f.read()
        
        # ä½¿ç”¨ä¼ å…¥çš„metadata_diræˆ–é»˜è®¤å€¼
        if metadata_dir is None:
            metadata_dir = METADATA_DIR
        self.metadata_dir = metadata_dir
    
    def cluster_clips(self, clips_with_titles: List[Dict]) -> List[Dict]:
        """
        å¯¹ç‰‡æ®µè¿›è¡Œä¸»é¢˜èšç±»
        
        Args:
            clips_with_titles: å¸¦æ ‡é¢˜çš„ç‰‡æ®µåˆ—è¡¨
            
        Returns:
            åˆé›†æ•°æ®åˆ—è¡¨
        """
        logger.info("å¼€å§‹è¿›è¡Œä¸»é¢˜èšç±»...")
        
        # å‡†å¤‡èšç±»æ•°æ®
        clips_for_clustering = []
        for clip in clips_with_titles:
            clips_for_clustering.append({
                'id': clip['id'],
                'title': clip.get('generated_title', clip['outline']),
                'summary': clip.get('recommend_reason', ''),
                'score': clip.get('final_score', 0)
            })
        
        # é¦–å…ˆè¿›è¡ŒåŸºäºå…³é”®è¯çš„é¢„èšç±»
        pre_clusters = self._pre_cluster_by_keywords(clips_for_clustering)
        
        # æ„å»ºå®Œæ•´çš„æç¤ºè¯
        full_prompt = self.clustering_prompt + "\n\nä»¥ä¸‹æ˜¯è§†é¢‘åˆ‡ç‰‡åˆ—è¡¨ï¼š\n"
        for i, clip in enumerate(clips_for_clustering, 1):
            full_prompt += f"{i}. æ ‡é¢˜ï¼š{clip['title']}\n   æ‘˜è¦ï¼š{clip['summary']}\n   è¯„åˆ†ï¼š{clip['score']:.2f}\n\n"
        
        # æ·»åŠ é¢„èšç±»ç»“æœä½œä¸ºå‚è€ƒ
        if pre_clusters:
            full_prompt += "\n\nåŸºäºå…³é”®è¯çš„é¢„èšç±»ç»“æœï¼ˆä»…ä¾›å‚è€ƒï¼‰ï¼š\n"
            for theme, clip_ids in pre_clusters.items():
                full_prompt += f"{theme}: {', '.join(clip_ids)}\n"
        
        try:
            # è°ƒç”¨å¤§æ¨¡å‹è¿›è¡Œèšç±»
            logger.info(f"ğŸš€ [èšç±»å¼€å§‹] è°ƒç”¨LLMè¿›è¡Œä¸»é¢˜èšç±»ï¼Œå¾…å¤„ç†ç‰‡æ®µæ•°: {len(clips_for_clustering)}")
            logger.info(f"ğŸ“„ [æç¤ºè¯é•¿åº¦]: {len(full_prompt)} å­—ç¬¦")
            logger.debug(f"ğŸ“„ [æç¤ºè¯é¢„è§ˆ]: {full_prompt[:500]}...")
            
            response = self.llm_client.call_with_retry(full_prompt)
            
            logger.info(f"âœ… [èšç±»å“åº”æˆåŠŸ] è·å¾—LLMå“åº”ï¼Œé•¿åº¦: {len(response) if response else 0} å­—ç¬¦")
            logger.debug(f"ğŸ“„ [èšç±»å“åº”å†…å®¹]: {response[:300] if response else 'N/A'}...")
            
            # è§£æJSONå“åº”
            logger.info(f"ğŸ” [å¼€å§‹è§£æ] è§£æLLMèšç±»å“åº”...")
            collections_data = self.llm_client.parse_json_response(response)
            
            # éªŒè¯å’Œæ¸…ç†åˆé›†æ•°æ®
            validated_collections = self._validate_collections(collections_data, clips_with_titles)
            
            # å¦‚æœLLMèšç±»ç»“æœä¸ç†æƒ³ï¼Œä½¿ç”¨é¢„èšç±»ç»“æœ
            if len(validated_collections) < 3:
                logger.warning("LLMèšç±»ç»“æœä¸ç†æƒ³ï¼Œä½¿ç”¨é¢„èšç±»ç»“æœ")
                validated_collections = self._create_collections_from_pre_clusters(pre_clusters, clips_with_titles)
            
            logger.info(f"ä¸»é¢˜èšç±»å®Œæˆï¼Œå…±{len(validated_collections)}ä¸ªåˆé›†")
            return validated_collections
            
        except Exception as e:
            logger.error(f"ä¸»é¢˜èšç±»å¤±è´¥: {str(e)}")
            # ä½¿ç”¨é¢„èšç±»ç»“æœä½œä¸ºå¤‡é€‰
            if pre_clusters:
                logger.info("ä½¿ç”¨é¢„èšç±»ç»“æœä½œä¸ºå¤‡é€‰æ–¹æ¡ˆ")
                return self._create_collections_from_pre_clusters(pre_clusters, clips_with_titles)
            # è¿”å›é»˜è®¤èšç±»ç»“æœ
            return self._create_default_collections(clips_with_titles)
    
    def _pre_cluster_by_keywords(self, clips: List[Dict]) -> Dict[str, List[str]]:
        """
        åŸºäºå…³é”®è¯è¿›è¡Œé¢„èšç±»
        
        Args:
            clips: ç‰‡æ®µåˆ—è¡¨
            
        Returns:
            é¢„èšç±»ç»“æœ
        """
        # å®šä¹‰ä¸»é¢˜å…³é”®è¯
        theme_keywords = {
            'æŠ•èµ„ç†è´¢': ['æŠ•èµ„', 'ç†è´¢', 'è‚¡ç¥¨', 'åŸºé‡‘', 'ç‚’è‚¡', 'èµšé’±', 'æ”¶ç›Š', 'æ¶¨è·Œ', 'è§£å¥—', 'æ•£æˆ·', 'Aè‚¡', 'åŒ—äº¤æ‰€', 'ä¸­å…', 'ç§ä¸š'],
            'èŒåœºæˆé•¿': ['èŒåœº', 'å·¥ä½œ', 'æŠ€èƒ½', 'å­¦ä¹ ', 'æ—¥è¯­', 'è‘£ç§˜', 'é€†è¢­', 'æ•™è‚²', 'å¤§å­¦ç”Ÿ', 'è´¢å•†'],
            'ç¤¾ä¼šè§‚å¯Ÿ': ['ç¤¾ä¼š', 'ç°è±¡', 'ç½‘ç»œ', 'ä¹±è±¡', 'åƒåœ¾', 'åˆ†ç±»', 'å¹³å°', 'æœºåˆ¶', 'ä¸»æ’­', 'è¡Œä¸š'],
            'æ–‡åŒ–å·®å¼‚': ['æ–‡åŒ–', 'å·®å¼‚', 'æ¬§ç¾', 'æ—¥æœ¬', 'éŸ©å›½', 'é¥®é£Ÿ', 'è¯­è¨€', 'ç‹è‡­', 'è’¸é”…', 'é‚®è½®'],
            'ç›´æ’­äº’åŠ¨': ['ç›´æ’­', 'äº’åŠ¨', 'å¼¹å¹•', 'ç²‰ä¸', 'èˆ°é•¿', 'æ‰“èµ', 'è¿éº¦', 'PK', 'æŠ½å¥–'],
            'æƒ…æ„Ÿå…³ç³»': ['æ‹çˆ±', 'æƒ…æ„Ÿ', 'ç¤¾äº¤', 'æ­è®ª', 'å…³ç³»', 'å¿ƒç†', 'å¿ƒåŠ¨', 'å†·æ·¡'],
            'å¥åº·ç”Ÿæ´»': ['å¥åº·', 'è¿åŠ¨', 'è·‘æ­¥', 'é¥®é£Ÿ', 'ç‰›å¥¶', 'ç”Ÿæ´»æ–¹å¼', 'é”»ç‚¼'],
            'åˆ›ä½œå¹³å°': ['åˆ›ä½œ', 'å¹³å°', 'Bç«™', 'å°çº¢ä¹¦', 'æ‘„å½±', 'å†…å®¹', 'è¿è¥', 'è‡ªåª’ä½“']
        }
        
        pre_clusters = {theme: [] for theme in theme_keywords.keys()}
        
        for clip in clips:
            # åˆå¹¶æ ‡é¢˜å’Œæ‘˜è¦è¿›è¡Œå…³é”®è¯åŒ¹é…
            text = f"{clip['title']} {clip['summary']}".lower()
            
            # è®¡ç®—æ¯ä¸ªä¸»é¢˜çš„åŒ¹é…åˆ†æ•°
            theme_scores = {}
            for theme, keywords in theme_keywords.items():
                score = sum(1 for keyword in keywords if keyword in text)
                if score > 0:
                    theme_scores[theme] = score
            
            # é€‰æ‹©åŒ¹é…åˆ†æ•°æœ€é«˜çš„ä¸»é¢˜
            if theme_scores:
                best_theme = max(theme_scores.keys(), key=lambda k: theme_scores[k])
                pre_clusters[best_theme].append(clip['id'])
        
        # è¿‡æ»¤æ‰ç©ºçš„ä¸»é¢˜
        return {theme: clip_ids for theme, clip_ids in pre_clusters.items() if len(clip_ids) >= 2}
    
    def _create_collections_from_pre_clusters(self, pre_clusters: Dict[str, List[str]], clips_with_titles: List[Dict]) -> List[Dict]:
        """
        ä»é¢„èšç±»ç»“æœåˆ›å»ºåˆé›†
        
        Args:
            pre_clusters: é¢„èšç±»ç»“æœ
            clips_with_titles: ç‰‡æ®µæ•°æ®
            
        Returns:
            åˆé›†æ•°æ®åˆ—è¡¨
        """
        collections = []
        collection_id = 1
        
        # ä¸»é¢˜æ ‡é¢˜æ˜ å°„
        theme_titles = {
            'æŠ•èµ„ç†è´¢': 'æŠ•èµ„ç†è´¢å¯ç¤º',
            'èŒåœºæˆé•¿': 'èŒåœºæˆé•¿è®°', 
            'ç¤¾ä¼šè§‚å¯Ÿ': 'ç¤¾ä¼šè§‚å¯Ÿç¬”è®°',
            'æ–‡åŒ–å·®å¼‚': 'æ–‡åŒ–å·®å¼‚è¶£è°ˆ',
            'ç›´æ’­äº’åŠ¨': 'ç›´æ’­äº’åŠ¨ç°åœº',
            'æƒ…æ„Ÿå…³ç³»': 'æƒ…æ„Ÿä¸å…³ç³»',
            'å¥åº·ç”Ÿæ´»': 'å¥åº·ç”Ÿæ´»æ–¹å¼',
            'åˆ›ä½œå¹³å°': 'åˆ›ä½œä¸å¹³å°ç”Ÿæ€'
        }
        
        # ä¸»é¢˜ç®€ä»‹æ˜ å°„
        theme_summaries = {
            'æŠ•èµ„ç†è´¢': 'é€šè¿‡ç”Ÿæ´»åŒ–æ¡ˆä¾‹åˆ†äº«æŠ•èµ„ç†å¿µï¼Œå…¼å…·å®ç”¨ä¸å…±é¸£ã€‚',
            'èŒåœºæˆé•¿': 'æ¢è®¨èŒä¸šå‘å±•ã€æŠ€èƒ½æå‡ä¸èŒåœºå¿ƒæ€å˜åŒ–ã€‚',
            'ç¤¾ä¼šè§‚å¯Ÿ': 'ç†æ€§ç‚¹è¯„ç¤¾ä¼šç°è±¡ä¸ç½‘ç»œä¹±è±¡ï¼Œè§‚ç‚¹é²œæ˜ã€‚',
            'æ–‡åŒ–å·®å¼‚': 'ä»é¥®é£Ÿåˆ°è¯­è¨€ï¼Œå±•ç°è·¨æ–‡åŒ–äº¤æµçš„è¶£å‘³è§†è§’ã€‚',
            'ç›´æ’­äº’åŠ¨': 'è¿˜åŸçœŸå®ç›´æ’­é—´äº’åŠ¨åœºæ™¯ï¼Œå±•ç°ä¸»æ’­ä¸´åœºååº”ã€‚',
            'æƒ…æ„Ÿå…³ç³»': 'è§£ææ‹çˆ±å¿ƒç†ã€ç¤¾äº¤å›°æƒ‘ä¸æƒ…æ„Ÿå…±é¸£è¯é¢˜ã€‚',
            'å¥åº·ç”Ÿæ´»': 'åˆ†äº«è¿åŠ¨ã€é¥®é£Ÿã€å¿ƒç†è°ƒé€‚ç­‰å¥åº·ç®¡ç†ç»éªŒã€‚',
            'åˆ›ä½œå¹³å°': 'å‰–æå†…å®¹åˆ›ä½œå›°å¢ƒä¸å¹³å°æœºåˆ¶ï¼Œé€‚åˆåˆ›ä½œè€…å‚è€ƒã€‚'
        }
        
        for theme, clip_ids in pre_clusters.items():
            # é™åˆ¶æ¯ä¸ªåˆé›†çš„ç‰‡æ®µæ•°é‡
            if len(clip_ids) > MAX_CLIPS_PER_COLLECTION:
                clip_ids = clip_ids[:MAX_CLIPS_PER_COLLECTION]
            
            collections.append({
                'id': str(collection_id),
                'collection_title': theme_titles.get(theme, theme),
                'collection_summary': theme_summaries.get(theme, f'{theme}ç›¸å…³ç²¾å½©ç‰‡æ®µåˆé›†'),
                'clip_ids': clip_ids
            })
            collection_id += 1
        
        return collections
    
    def _validate_collections(self, collections_data: List[Dict], clips_with_titles: List[Dict]) -> List[Dict]:
        """
        éªŒè¯å’Œæ¸…ç†åˆé›†æ•°æ®
        
        Args:
            collections_data: åŸå§‹åˆé›†æ•°æ®
            clips_with_titles: ç‰‡æ®µæ•°æ®
            
        Returns:
            éªŒè¯åçš„åˆé›†æ•°æ®
        """
        validated_collections = []
        
        for i, collection in enumerate(collections_data):
            try:
                # éªŒè¯å¿…éœ€å­—æ®µ
                if not all(key in collection for key in ['collection_title', 'collection_summary', 'clips']):
                    logger.warning(f"åˆé›† {i} ç¼ºå°‘å¿…éœ€å­—æ®µï¼Œè·³è¿‡")
                    continue
                
                # éªŒè¯ç‰‡æ®µåˆ—è¡¨
                clip_titles = collection['clips']
                valid_clip_ids = []
                
                for clip_title in clip_titles:
                    # æ ¹æ®æ ‡é¢˜æ‰¾åˆ°å¯¹åº”çš„ç‰‡æ®µID
                    for clip in clips_with_titles:
                        if (clip.get('generated_title', clip['outline']) == clip_title or 
                            clip['outline'] == clip_title):
                            valid_clip_ids.append(clip['id'])
                            break
                
                if len(valid_clip_ids) < 2:
                    logger.warning(f"åˆé›† {i} æœ‰æ•ˆç‰‡æ®µå°‘äº2ä¸ªï¼Œè·³è¿‡")
                    continue
                
                # é™åˆ¶æ¯ä¸ªåˆé›†çš„ç‰‡æ®µæ•°é‡
                if len(valid_clip_ids) > MAX_CLIPS_PER_COLLECTION:
                    valid_clip_ids = valid_clip_ids[:MAX_CLIPS_PER_COLLECTION]
                
                validated_collection = {
                    'id': str(i + 1),
                    'collection_title': collection['collection_title'],
                    'collection_summary': collection['collection_summary'],
                    'clip_ids': valid_clip_ids
                }
                
                validated_collections.append(validated_collection)
                
            except Exception as e:
                logger.error(f"éªŒè¯åˆé›† {i} å¤±è´¥: {str(e)}")
                continue
        
        return validated_collections
    
    def _create_default_collections(self, clips_with_titles: List[Dict]) -> List[Dict]:
        """
        åˆ›å»ºé»˜è®¤åˆé›†ï¼ˆå½“èšç±»å¤±è´¥æ—¶ï¼‰
        
        Args:
            clips_with_titles: ç‰‡æ®µæ•°æ®
            
        Returns:
            é»˜è®¤åˆé›†æ•°æ®
        """
        logger.info("åˆ›å»ºé»˜è®¤åˆé›†...")
        
        # æŒ‰è¯„åˆ†åˆ†ç»„
        high_score = []
        medium_score = []
        
        for clip in clips_with_titles:
            score = clip.get('final_score', 0)
            if score >= 0.8:
                high_score.append(clip)
            elif score >= 0.6:
                medium_score.append(clip)
        
        collections = []
        
        # åˆ›å»ºé«˜åˆ†åˆé›†
        if len(high_score) >= 2:
            collections.append({
                'id': '1',
                'collection_title': 'ç²¾é€‰é«˜åˆ†ç‰‡æ®µ',
                'collection_summary': 'è¯„åˆ†æœ€é«˜çš„ç²¾å½©ç‰‡æ®µåˆé›†',
                'clip_ids': [clip['id'] for clip in high_score[:MAX_CLIPS_PER_COLLECTION]]
            })
        
        # åˆ›å»ºä¸­ç­‰åˆ†åˆé›†
        if len(medium_score) >= 2:
            collections.append({
                'id': '2',
                'collection_title': 'ä¼˜è´¨å†…å®¹æ¨è',
                'collection_summary': 'ç²¾é€‰ä¼˜è´¨å†…å®¹ç‰‡æ®µ',
                'clip_ids': [clip['id'] for clip in medium_score[:MAX_CLIPS_PER_COLLECTION]]
            })
        
        return collections
    
    def save_collections(self, collections_data: List[Dict], output_path: Optional[Path] = None) -> Path:
        """
        ä¿å­˜åˆé›†æ•°æ®
        
        Args:
            collections_data: åˆé›†æ•°æ®
            output_path: è¾“å‡ºè·¯å¾„
            
        Returns:
            ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
        """
        if output_path is None:
            output_path = self.metadata_dir / "collections.json"
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        # ä¿å­˜æ•°æ®
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(collections_data, f, ensure_ascii=False, indent=2)
        
        logger.info(f"åˆé›†æ•°æ®å·²ä¿å­˜åˆ°: {output_path}")
        return output_path
    
    def load_collections(self, input_path: Path) -> List[Dict]:
        """
        ä»æ–‡ä»¶åŠ è½½åˆé›†æ•°æ®
        
        Args:
            input_path: è¾“å…¥æ–‡ä»¶è·¯å¾„
            
        Returns:
            åˆé›†æ•°æ®
        """
        with open(input_path, 'r', encoding='utf-8') as f:
            return json.load(f)

def run_step5_clustering(clips_with_titles_path: Path, output_path: Optional[Path] = None, metadata_dir: Optional[str] = None, prompt_files: Dict = None) -> List[Dict]:
    """
    è¿è¡ŒStep 5: ä¸»é¢˜èšç±»
    
    Args:
        clips_with_titles_path: å¸¦æ ‡é¢˜çš„ç‰‡æ®µæ–‡ä»¶è·¯å¾„
        output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        prompt_files: è‡ªå®šä¹‰æç¤ºè¯æ–‡ä»¶
        
    Returns:
        åˆé›†æ•°æ®
    """
    # åŠ è½½æ•°æ®
    with open(clips_with_titles_path, 'r', encoding='utf-8') as f:
        clips_with_titles = json.load(f)
    
    # åˆ›å»ºèšç±»å™¨
    if metadata_dir is None:
        metadata_dir = METADATA_DIR
    clusterer = ClusteringEngine(metadata_dir=Path(metadata_dir), prompt_files=prompt_files)
    
    # è¿›è¡Œèšç±»
    collections_data = clusterer.cluster_clips(clips_with_titles)
    
    # ä¿å­˜ç»“æœ
    if output_path is None:
        if metadata_dir is None:
            metadata_dir = METADATA_DIR
        output_path = Path(metadata_dir) / "step5_collections.json"
    
    clusterer.save_collections(collections_data, output_path)
    
    return collections_data